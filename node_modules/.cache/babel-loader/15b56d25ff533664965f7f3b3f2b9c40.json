{"ast":null,"code":"/*\n\tMIT License http://www.opensource.org/licenses/mit-license.php\n\tAuthor Tobias Koppers @sokra\n*/\n\"use strict\";\n\nvar _slicedToArray = require(\"/home/hari/Desktop/web-dev/React/cstudy/node_modules/@babel/runtime/helpers/slicedToArray\");\n\nconst crypto = require(\"crypto\");\n\nconst SortableSet = require(\"../util/SortableSet\");\n\nconst GraphHelpers = require(\"../GraphHelpers\");\n\nconst _require = require(\"../util/SetHelpers\"),\n      isSubset = _require.isSubset;\n\nconst deterministicGrouping = require(\"../util/deterministicGrouping\");\n\nconst MinMaxSizeWarning = require(\"./MinMaxSizeWarning\");\n\nconst contextify = require(\"../util/identifier\").contextify;\n/** @typedef {import(\"../Compiler\")} Compiler */\n\n/** @typedef {import(\"../Chunk\")} Chunk */\n\n/** @typedef {import(\"../Module\")} Module */\n\n/** @typedef {import(\"../util/deterministicGrouping\").Options<Module>} DeterministicGroupingOptionsForModule */\n\n/** @typedef {import(\"../util/deterministicGrouping\").GroupedItems<Module>} DeterministicGroupingGroupedItemsForModule */\n\n\nconst deterministicGroupingForModules =\n/** @type {function(DeterministicGroupingOptionsForModule): DeterministicGroupingGroupedItemsForModule[]} */\ndeterministicGrouping;\n\nconst hashFilename = name => {\n  return crypto.createHash(\"md4\").update(name).digest(\"hex\").slice(0, 8);\n};\n\nconst sortByIdentifier = (a, b) => {\n  if (a.identifier() > b.identifier()) return 1;\n  if (a.identifier() < b.identifier()) return -1;\n  return 0;\n};\n\nconst getRequests = chunk => {\n  let requests = 0;\n\n  for (const chunkGroup of chunk.groupsIterable) {\n    requests = Math.max(requests, chunkGroup.chunks.length);\n  }\n\n  return requests;\n};\n\nconst getModulesSize = modules => {\n  let sum = 0;\n\n  for (const m of modules) {\n    sum += m.size();\n  }\n\n  return sum;\n};\n/**\n * @template T\n * @param {Set<T>} a set\n * @param {Set<T>} b other set\n * @returns {boolean} true if at least one item of a is in b\n */\n\n\nconst isOverlap = (a, b) => {\n  for (const item of a) {\n    if (b.has(item)) return true;\n  }\n\n  return false;\n};\n\nconst compareEntries = (a, b) => {\n  // 1. by priority\n  const diffPriority = a.cacheGroup.priority - b.cacheGroup.priority;\n  if (diffPriority) return diffPriority; // 2. by number of chunks\n\n  const diffCount = a.chunks.size - b.chunks.size;\n  if (diffCount) return diffCount; // 3. by size reduction\n\n  const aSizeReduce = a.size * (a.chunks.size - 1);\n  const bSizeReduce = b.size * (b.chunks.size - 1);\n  const diffSizeReduce = aSizeReduce - bSizeReduce;\n  if (diffSizeReduce) return diffSizeReduce; // 4. by number of modules (to be able to compare by identifier)\n\n  const modulesA = a.modules;\n  const modulesB = b.modules;\n  const diff = modulesA.size - modulesB.size;\n  if (diff) return diff; // 5. by module identifiers\n\n  modulesA.sort();\n  modulesB.sort();\n  const aI = modulesA[Symbol.iterator]();\n  const bI = modulesB[Symbol.iterator](); // eslint-disable-next-line no-constant-condition\n\n  while (true) {\n    const aItem = aI.next();\n    const bItem = bI.next();\n    if (aItem.done) return 0;\n    const aModuleIdentifier = aItem.value.identifier();\n    const bModuleIdentifier = bItem.value.identifier();\n    if (aModuleIdentifier > bModuleIdentifier) return -1;\n    if (aModuleIdentifier < bModuleIdentifier) return 1;\n  }\n};\n\nconst compareNumbers = (a, b) => a - b;\n\nconst INITIAL_CHUNK_FILTER = chunk => chunk.canBeInitial();\n\nconst ASYNC_CHUNK_FILTER = chunk => !chunk.canBeInitial();\n\nconst ALL_CHUNK_FILTER = chunk => true;\n\nmodule.exports = class SplitChunksPlugin {\n  constructor(options) {\n    this.options = SplitChunksPlugin.normalizeOptions(options);\n  }\n\n  static normalizeOptions(options = {}) {\n    return {\n      chunksFilter: SplitChunksPlugin.normalizeChunksFilter(options.chunks || \"all\"),\n      minSize: options.minSize || 0,\n      maxSize: options.maxSize || 0,\n      minChunks: options.minChunks || 1,\n      maxAsyncRequests: options.maxAsyncRequests || 1,\n      maxInitialRequests: options.maxInitialRequests || 1,\n      hidePathInfo: options.hidePathInfo || false,\n      filename: options.filename || undefined,\n      getCacheGroups: SplitChunksPlugin.normalizeCacheGroups({\n        cacheGroups: options.cacheGroups,\n        name: options.name,\n        automaticNameDelimiter: options.automaticNameDelimiter,\n        automaticNameMaxLength: options.automaticNameMaxLength\n      }),\n      automaticNameDelimiter: options.automaticNameDelimiter,\n      automaticNameMaxLength: options.automaticNameMaxLength || 109,\n      fallbackCacheGroup: SplitChunksPlugin.normalizeFallbackCacheGroup(options.fallbackCacheGroup || {}, options)\n    };\n  }\n\n  static normalizeName({\n    name,\n    automaticNameDelimiter,\n    automaticNamePrefix,\n    automaticNameMaxLength\n  }) {\n    if (name === true) {\n      /** @type {WeakMap<Chunk[], Record<string, string>>} */\n      const cache = new WeakMap();\n\n      const fn = (module, chunks, cacheGroup) => {\n        let cacheEntry = cache.get(chunks);\n\n        if (cacheEntry === undefined) {\n          cacheEntry = {};\n          cache.set(chunks, cacheEntry);\n        } else if (cacheGroup in cacheEntry) {\n          return cacheEntry[cacheGroup];\n        }\n\n        const names = chunks.map(c => c.name);\n\n        if (!names.every(Boolean)) {\n          cacheEntry[cacheGroup] = undefined;\n          return;\n        }\n\n        names.sort();\n        const prefix = typeof automaticNamePrefix === \"string\" ? automaticNamePrefix : cacheGroup;\n        const namePrefix = prefix ? prefix + automaticNameDelimiter : \"\";\n        let name = namePrefix + names.join(automaticNameDelimiter); // Filenames and paths can't be too long otherwise an\n        // ENAMETOOLONG error is raised. If the generated name if too\n        // long, it is truncated and a hash is appended. The limit has\n        // been set to 109 to prevent `[name].[chunkhash].[ext]` from\n        // generating a 256+ character string.\n\n        if (name.length > automaticNameMaxLength) {\n          const hashedFilename = hashFilename(name);\n          const sliceLength = automaticNameMaxLength - (automaticNameDelimiter.length + hashedFilename.length);\n          name = name.slice(0, sliceLength) + automaticNameDelimiter + hashFilename(name);\n        }\n\n        cacheEntry[cacheGroup] = name;\n        return name;\n      };\n\n      return fn;\n    }\n\n    if (typeof name === \"string\") {\n      const fn = () => {\n        return name;\n      };\n\n      return fn;\n    }\n\n    if (typeof name === \"function\") return name;\n  }\n\n  static normalizeChunksFilter(chunks) {\n    if (chunks === \"initial\") {\n      return INITIAL_CHUNK_FILTER;\n    }\n\n    if (chunks === \"async\") {\n      return ASYNC_CHUNK_FILTER;\n    }\n\n    if (chunks === \"all\") {\n      return ALL_CHUNK_FILTER;\n    }\n\n    if (typeof chunks === \"function\") return chunks;\n  }\n\n  static normalizeFallbackCacheGroup({\n    minSize = undefined,\n    maxSize = undefined,\n    automaticNameDelimiter = undefined\n  }, {\n    minSize: defaultMinSize = undefined,\n    maxSize: defaultMaxSize = undefined,\n    automaticNameDelimiter: defaultAutomaticNameDelimiter = undefined\n  }) {\n    return {\n      minSize: typeof minSize === \"number\" ? minSize : defaultMinSize || 0,\n      maxSize: typeof maxSize === \"number\" ? maxSize : defaultMaxSize || 0,\n      automaticNameDelimiter: automaticNameDelimiter || defaultAutomaticNameDelimiter || \"~\"\n    };\n  }\n\n  static normalizeCacheGroups({\n    cacheGroups,\n    name,\n    automaticNameDelimiter,\n    automaticNameMaxLength\n  }) {\n    if (typeof cacheGroups === \"function\") {\n      // TODO webpack 5 remove this\n      if (cacheGroups.length !== 1) {\n        return module => cacheGroups(module, module.getChunks());\n      }\n\n      return cacheGroups;\n    }\n\n    if (cacheGroups && typeof cacheGroups === \"object\") {\n      const fn = module => {\n        let results;\n\n        for (const key of Object.keys(cacheGroups)) {\n          let option = cacheGroups[key];\n          if (option === false) continue;\n\n          if (option instanceof RegExp || typeof option === \"string\") {\n            option = {\n              test: option\n            };\n          }\n\n          if (typeof option === \"function\") {\n            let result = option(module);\n\n            if (result) {\n              if (results === undefined) results = [];\n\n              for (const r of Array.isArray(result) ? result : [result]) {\n                const result = Object.assign({\n                  key\n                }, r);\n                if (result.name) result.getName = () => result.name;\n\n                if (result.chunks) {\n                  result.chunksFilter = SplitChunksPlugin.normalizeChunksFilter(result.chunks);\n                }\n\n                results.push(result);\n              }\n            }\n          } else if (SplitChunksPlugin.checkTest(option.test, module)) {\n            if (results === undefined) results = [];\n            results.push({\n              key: key,\n              priority: option.priority,\n              getName: SplitChunksPlugin.normalizeName({\n                name: option.name || name,\n                automaticNameDelimiter: typeof option.automaticNameDelimiter === \"string\" ? option.automaticNameDelimiter : automaticNameDelimiter,\n                automaticNamePrefix: option.automaticNamePrefix,\n                automaticNameMaxLength: option.automaticNameMaxLength || automaticNameMaxLength\n              }) || (() => {}),\n              chunksFilter: SplitChunksPlugin.normalizeChunksFilter(option.chunks),\n              enforce: option.enforce,\n              minSize: option.minSize,\n              maxSize: option.maxSize,\n              minChunks: option.minChunks,\n              maxAsyncRequests: option.maxAsyncRequests,\n              maxInitialRequests: option.maxInitialRequests,\n              filename: option.filename,\n              reuseExistingChunk: option.reuseExistingChunk\n            });\n          }\n        }\n\n        return results;\n      };\n\n      return fn;\n    }\n\n    const fn = () => {};\n\n    return fn;\n  }\n\n  static checkTest(test, module) {\n    if (test === undefined) return true;\n\n    if (typeof test === \"function\") {\n      if (test.length !== 1) {\n        return test(module, module.getChunks());\n      }\n\n      return test(module);\n    }\n\n    if (typeof test === \"boolean\") return test;\n\n    if (typeof test === \"string\") {\n      if (module.nameForCondition && module.nameForCondition().startsWith(test)) {\n        return true;\n      }\n\n      for (const chunk of module.chunksIterable) {\n        if (chunk.name && chunk.name.startsWith(test)) {\n          return true;\n        }\n      }\n\n      return false;\n    }\n\n    if (test instanceof RegExp) {\n      if (module.nameForCondition && test.test(module.nameForCondition())) {\n        return true;\n      }\n\n      for (const chunk of module.chunksIterable) {\n        if (chunk.name && test.test(chunk.name)) {\n          return true;\n        }\n      }\n\n      return false;\n    }\n\n    return false;\n  }\n  /**\n   * @param {Compiler} compiler webpack compiler\n   * @returns {void}\n   */\n\n\n  apply(compiler) {\n    compiler.hooks.thisCompilation.tap(\"SplitChunksPlugin\", compilation => {\n      let alreadyOptimized = false;\n      compilation.hooks.unseal.tap(\"SplitChunksPlugin\", () => {\n        alreadyOptimized = false;\n      });\n      compilation.hooks.optimizeChunksAdvanced.tap(\"SplitChunksPlugin\", chunks => {\n        if (alreadyOptimized) return;\n        alreadyOptimized = true; // Give each selected chunk an index (to create strings from chunks)\n\n        const indexMap = new Map();\n        let index = 1;\n\n        for (const chunk of chunks) {\n          indexMap.set(chunk, index++);\n        }\n\n        const getKey = chunks => {\n          return Array.from(chunks, c => indexMap.get(c)).sort(compareNumbers).join();\n        };\n        /** @type {Map<string, Set<Chunk>>} */\n\n\n        const chunkSetsInGraph = new Map();\n\n        for (const module of compilation.modules) {\n          const chunksKey = getKey(module.chunksIterable);\n\n          if (!chunkSetsInGraph.has(chunksKey)) {\n            chunkSetsInGraph.set(chunksKey, new Set(module.chunksIterable));\n          }\n        } // group these set of chunks by count\n        // to allow to check less sets via isSubset\n        // (only smaller sets can be subset)\n\n        /** @type {Map<number, Array<Set<Chunk>>>} */\n\n\n        const chunkSetsByCount = new Map();\n\n        for (const chunksSet of chunkSetsInGraph.values()) {\n          const count = chunksSet.size;\n          let array = chunkSetsByCount.get(count);\n\n          if (array === undefined) {\n            array = [];\n            chunkSetsByCount.set(count, array);\n          }\n\n          array.push(chunksSet);\n        } // Create a list of possible combinations\n\n\n        const combinationsCache = new Map(); // Map<string, Set<Chunk>[]>\n\n        const getCombinations = key => {\n          const chunksSet = chunkSetsInGraph.get(key);\n          var array = [chunksSet];\n\n          if (chunksSet.size > 1) {\n            for (const _ref of chunkSetsByCount) {\n              var _ref2 = _slicedToArray(_ref, 2);\n\n              const count = _ref2[0];\n              const setArray = _ref2[1];\n\n              // \"equal\" is not needed because they would have been merge in the first step\n              if (count < chunksSet.size) {\n                for (const set of setArray) {\n                  if (isSubset(chunksSet, set)) {\n                    array.push(set);\n                  }\n                }\n              }\n            }\n          }\n\n          return array;\n        };\n        /**\n         * @typedef {Object} SelectedChunksResult\n         * @property {Chunk[]} chunks the list of chunks\n         * @property {string} key a key of the list\n         */\n\n        /**\n         * @typedef {function(Chunk): boolean} ChunkFilterFunction\n         */\n\n        /** @type {WeakMap<Set<Chunk>, WeakMap<ChunkFilterFunction, SelectedChunksResult>>} */\n\n\n        const selectedChunksCacheByChunksSet = new WeakMap();\n        /**\n         * get list and key by applying the filter function to the list\n         * It is cached for performance reasons\n         * @param {Set<Chunk>} chunks list of chunks\n         * @param {ChunkFilterFunction} chunkFilter filter function for chunks\n         * @returns {SelectedChunksResult} list and key\n         */\n\n        const getSelectedChunks = (chunks, chunkFilter) => {\n          let entry = selectedChunksCacheByChunksSet.get(chunks);\n\n          if (entry === undefined) {\n            entry = new WeakMap();\n            selectedChunksCacheByChunksSet.set(chunks, entry);\n          }\n          /** @type {SelectedChunksResult} */\n\n\n          let entry2 = entry.get(chunkFilter);\n\n          if (entry2 === undefined) {\n            /** @type {Chunk[]} */\n            const selectedChunks = [];\n\n            for (const chunk of chunks) {\n              if (chunkFilter(chunk)) selectedChunks.push(chunk);\n            }\n\n            entry2 = {\n              chunks: selectedChunks,\n              key: getKey(selectedChunks)\n            };\n            entry.set(chunkFilter, entry2);\n          }\n\n          return entry2;\n        };\n        /**\n         * @typedef {Object} ChunksInfoItem\n         * @property {SortableSet} modules\n         * @property {TODO} cacheGroup\n         * @property {string} name\n         * @property {boolean} validateSize\n         * @property {number} size\n         * @property {Set<Chunk>} chunks\n         * @property {Set<Chunk>} reuseableChunks\n         * @property {Set<string>} chunksKeys\n         */\n        // Map a list of chunks to a list of modules\n        // For the key the chunk \"index\" is used, the value is a SortableSet of modules\n\n        /** @type {Map<string, ChunksInfoItem>} */\n\n\n        const chunksInfoMap = new Map();\n        /**\n         * @param {TODO} cacheGroup the current cache group\n         * @param {Chunk[]} selectedChunks chunks selected for this module\n         * @param {string} selectedChunksKey a key of selectedChunks\n         * @param {Module} module the current module\n         * @returns {void}\n         */\n\n        const addModuleToChunksInfoMap = (cacheGroup, selectedChunks, selectedChunksKey, module) => {\n          // Break if minimum number of chunks is not reached\n          if (selectedChunks.length < cacheGroup.minChunks) return; // Determine name for split chunk\n\n          const name = cacheGroup.getName(module, selectedChunks, cacheGroup.key); // Create key for maps\n          // When it has a name we use the name as key\n          // Elsewise we create the key from chunks and cache group key\n          // This automatically merges equal names\n\n          const key = cacheGroup.key + (name ? \" name:\".concat(name) : \" chunks:\".concat(selectedChunksKey)); // Add module to maps\n\n          let info = chunksInfoMap.get(key);\n\n          if (info === undefined) {\n            chunksInfoMap.set(key, info = {\n              modules: new SortableSet(undefined, sortByIdentifier),\n              cacheGroup,\n              name,\n              validateSize: cacheGroup.minSize > 0,\n              size: 0,\n              chunks: new Set(),\n              reuseableChunks: new Set(),\n              chunksKeys: new Set()\n            });\n          }\n\n          info.modules.add(module);\n\n          if (info.validateSize) {\n            info.size += module.size();\n          }\n\n          if (!info.chunksKeys.has(selectedChunksKey)) {\n            info.chunksKeys.add(selectedChunksKey);\n\n            for (const chunk of selectedChunks) {\n              info.chunks.add(chunk);\n            }\n          }\n        }; // Walk through all modules\n\n\n        for (const module of compilation.modules) {\n          // Get cache group\n          let cacheGroups = this.options.getCacheGroups(module);\n\n          if (!Array.isArray(cacheGroups) || cacheGroups.length === 0) {\n            continue;\n          } // Prepare some values\n\n\n          const chunksKey = getKey(module.chunksIterable);\n          let combs = combinationsCache.get(chunksKey);\n\n          if (combs === undefined) {\n            combs = getCombinations(chunksKey);\n            combinationsCache.set(chunksKey, combs);\n          }\n\n          for (const cacheGroupSource of cacheGroups) {\n            const cacheGroup = {\n              key: cacheGroupSource.key,\n              priority: cacheGroupSource.priority || 0,\n              chunksFilter: cacheGroupSource.chunksFilter || this.options.chunksFilter,\n              minSize: cacheGroupSource.minSize !== undefined ? cacheGroupSource.minSize : cacheGroupSource.enforce ? 0 : this.options.minSize,\n              minSizeForMaxSize: cacheGroupSource.minSize !== undefined ? cacheGroupSource.minSize : this.options.minSize,\n              maxSize: cacheGroupSource.maxSize !== undefined ? cacheGroupSource.maxSize : cacheGroupSource.enforce ? 0 : this.options.maxSize,\n              minChunks: cacheGroupSource.minChunks !== undefined ? cacheGroupSource.minChunks : cacheGroupSource.enforce ? 1 : this.options.minChunks,\n              maxAsyncRequests: cacheGroupSource.maxAsyncRequests !== undefined ? cacheGroupSource.maxAsyncRequests : cacheGroupSource.enforce ? Infinity : this.options.maxAsyncRequests,\n              maxInitialRequests: cacheGroupSource.maxInitialRequests !== undefined ? cacheGroupSource.maxInitialRequests : cacheGroupSource.enforce ? Infinity : this.options.maxInitialRequests,\n              getName: cacheGroupSource.getName !== undefined ? cacheGroupSource.getName : this.options.getName,\n              filename: cacheGroupSource.filename !== undefined ? cacheGroupSource.filename : this.options.filename,\n              automaticNameDelimiter: cacheGroupSource.automaticNameDelimiter !== undefined ? cacheGroupSource.automaticNameDelimiter : this.options.automaticNameDelimiter,\n              reuseExistingChunk: cacheGroupSource.reuseExistingChunk\n            }; // For all combination of chunk selection\n\n            for (const chunkCombination of combs) {\n              // Break if minimum number of chunks is not reached\n              if (chunkCombination.size < cacheGroup.minChunks) continue; // Select chunks by configuration\n\n              const _getSelectedChunks = getSelectedChunks(chunkCombination, cacheGroup.chunksFilter),\n                    selectedChunks = _getSelectedChunks.chunks,\n                    selectedChunksKey = _getSelectedChunks.key;\n\n              addModuleToChunksInfoMap(cacheGroup, selectedChunks, selectedChunksKey, module);\n            }\n          }\n        } // Filter items were size < minSize\n\n\n        for (const pair of chunksInfoMap) {\n          const info = pair[1];\n\n          if (info.validateSize && info.size < info.cacheGroup.minSize) {\n            chunksInfoMap.delete(pair[0]);\n          }\n        }\n        /** @type {Map<Chunk, {minSize: number, maxSize: number, automaticNameDelimiter: string, keys: string[]}>} */\n\n\n        const maxSizeQueueMap = new Map();\n\n        while (chunksInfoMap.size > 0) {\n          // Find best matching entry\n          let bestEntryKey;\n          let bestEntry;\n\n          for (const pair of chunksInfoMap) {\n            const key = pair[0];\n            const info = pair[1];\n\n            if (bestEntry === undefined) {\n              bestEntry = info;\n              bestEntryKey = key;\n            } else if (compareEntries(bestEntry, info) < 0) {\n              bestEntry = info;\n              bestEntryKey = key;\n            }\n          }\n\n          const item = bestEntry;\n          chunksInfoMap.delete(bestEntryKey);\n          let chunkName = item.name; // Variable for the new chunk (lazy created)\n\n          /** @type {Chunk} */\n\n          let newChunk; // When no chunk name, check if we can reuse a chunk instead of creating a new one\n\n          let isReused = false;\n\n          if (item.cacheGroup.reuseExistingChunk) {\n            outer: for (const chunk of item.chunks) {\n              if (chunk.getNumberOfModules() !== item.modules.size) continue;\n              if (chunk.hasEntryModule()) continue;\n\n              for (const module of item.modules) {\n                if (!chunk.containsModule(module)) continue outer;\n              }\n\n              if (!newChunk || !newChunk.name) {\n                newChunk = chunk;\n              } else if (chunk.name && chunk.name.length < newChunk.name.length) {\n                newChunk = chunk;\n              } else if (chunk.name && chunk.name.length === newChunk.name.length && chunk.name < newChunk.name) {\n                newChunk = chunk;\n              }\n\n              chunkName = undefined;\n              isReused = true;\n            }\n          } // Check if maxRequests condition can be fulfilled\n\n\n          const usedChunks = Array.from(item.chunks).filter(chunk => {\n            // skip if we address ourself\n            return (!chunkName || chunk.name !== chunkName) && chunk !== newChunk;\n          }); // Skip when no chunk selected\n\n          if (usedChunks.length === 0) continue;\n          let validChunks = usedChunks;\n\n          if (Number.isFinite(item.cacheGroup.maxInitialRequests) || Number.isFinite(item.cacheGroup.maxAsyncRequests)) {\n            validChunks = validChunks.filter(chunk => {\n              // respect max requests when not enforced\n              const maxRequests = chunk.isOnlyInitial() ? item.cacheGroup.maxInitialRequests : chunk.canBeInitial() ? Math.min(item.cacheGroup.maxInitialRequests, item.cacheGroup.maxAsyncRequests) : item.cacheGroup.maxAsyncRequests;\n              return !isFinite(maxRequests) || getRequests(chunk) < maxRequests;\n            });\n          }\n\n          validChunks = validChunks.filter(chunk => {\n            for (const module of item.modules) {\n              if (chunk.containsModule(module)) return true;\n            }\n\n            return false;\n          });\n\n          if (validChunks.length < usedChunks.length) {\n            if (validChunks.length >= item.cacheGroup.minChunks) {\n              for (const module of item.modules) {\n                addModuleToChunksInfoMap(item.cacheGroup, validChunks, getKey(validChunks), module);\n              }\n            }\n\n            continue;\n          } // Create the new chunk if not reusing one\n\n\n          if (!isReused) {\n            newChunk = compilation.addChunk(chunkName);\n          } // Walk through all chunks\n\n\n          for (const chunk of usedChunks) {\n            // Add graph connections for splitted chunk\n            chunk.split(newChunk);\n          } // Add a note to the chunk\n\n\n          newChunk.chunkReason = isReused ? \"reused as split chunk\" : \"split chunk\";\n\n          if (item.cacheGroup.key) {\n            newChunk.chunkReason += \" (cache group: \".concat(item.cacheGroup.key, \")\");\n          }\n\n          if (chunkName) {\n            newChunk.chunkReason += \" (name: \".concat(chunkName, \")\"); // If the chosen name is already an entry point we remove the entry point\n\n            const entrypoint = compilation.entrypoints.get(chunkName);\n\n            if (entrypoint) {\n              compilation.entrypoints.delete(chunkName);\n              entrypoint.remove();\n              newChunk.entryModule = undefined;\n            }\n          }\n\n          if (item.cacheGroup.filename) {\n            if (!newChunk.isOnlyInitial()) {\n              throw new Error(\"SplitChunksPlugin: You are trying to set a filename for a chunk which is (also) loaded on demand. \" + \"The runtime can only handle loading of chunks which match the chunkFilename schema. \" + \"Using a custom filename would fail at runtime. \" + \"(cache group: \".concat(item.cacheGroup.key, \")\"));\n            }\n\n            newChunk.filenameTemplate = item.cacheGroup.filename;\n          }\n\n          if (!isReused) {\n            // Add all modules to the new chunk\n            for (const module of item.modules) {\n              if (typeof module.chunkCondition === \"function\") {\n                if (!module.chunkCondition(newChunk)) continue;\n              } // Add module to new chunk\n\n\n              GraphHelpers.connectChunkAndModule(newChunk, module); // Remove module from used chunks\n\n              for (const chunk of usedChunks) {\n                chunk.removeModule(module);\n                module.rewriteChunkInReasons(chunk, [newChunk]);\n              }\n            }\n          } else {\n            // Remove all modules from used chunks\n            for (const module of item.modules) {\n              for (const chunk of usedChunks) {\n                chunk.removeModule(module);\n                module.rewriteChunkInReasons(chunk, [newChunk]);\n              }\n            }\n          }\n\n          if (item.cacheGroup.maxSize > 0) {\n            const oldMaxSizeSettings = maxSizeQueueMap.get(newChunk);\n            maxSizeQueueMap.set(newChunk, {\n              minSize: Math.max(oldMaxSizeSettings ? oldMaxSizeSettings.minSize : 0, item.cacheGroup.minSizeForMaxSize),\n              maxSize: Math.min(oldMaxSizeSettings ? oldMaxSizeSettings.maxSize : Infinity, item.cacheGroup.maxSize),\n              automaticNameDelimiter: item.cacheGroup.automaticNameDelimiter,\n              keys: oldMaxSizeSettings ? oldMaxSizeSettings.keys.concat(item.cacheGroup.key) : [item.cacheGroup.key]\n            });\n          } // remove all modules from other entries and update size\n\n\n          for (const _ref3 of chunksInfoMap) {\n            var _ref4 = _slicedToArray(_ref3, 2);\n\n            const key = _ref4[0];\n            const info = _ref4[1];\n\n            if (isOverlap(info.chunks, item.chunks)) {\n              if (info.validateSize) {\n                // update modules and total size\n                // may remove it from the map when < minSize\n                const oldSize = info.modules.size;\n\n                for (const module of item.modules) {\n                  info.modules.delete(module);\n                }\n\n                if (info.modules.size === 0) {\n                  chunksInfoMap.delete(key);\n                  continue;\n                }\n\n                if (info.modules.size !== oldSize) {\n                  info.size = getModulesSize(info.modules);\n\n                  if (info.size < info.cacheGroup.minSize) {\n                    chunksInfoMap.delete(key);\n                  }\n                }\n              } else {\n                // only update the modules\n                for (const module of item.modules) {\n                  info.modules.delete(module);\n                }\n\n                if (info.modules.size === 0) {\n                  chunksInfoMap.delete(key);\n                }\n              }\n            }\n          }\n        }\n\n        const incorrectMinMaxSizeSet = new Set(); // Make sure that maxSize is fulfilled\n\n        for (const chunk of compilation.chunks.slice()) {\n          const _ref5 = maxSizeQueueMap.get(chunk) || this.options.fallbackCacheGroup,\n                minSize = _ref5.minSize,\n                maxSize = _ref5.maxSize,\n                automaticNameDelimiter = _ref5.automaticNameDelimiter,\n                keys = _ref5.keys;\n\n          if (!maxSize) continue;\n\n          if (minSize > maxSize) {\n            const warningKey = \"\".concat(keys && keys.join(), \" \").concat(minSize, \" \").concat(maxSize);\n\n            if (!incorrectMinMaxSizeSet.has(warningKey)) {\n              incorrectMinMaxSizeSet.add(warningKey);\n              compilation.warnings.push(new MinMaxSizeWarning(keys, minSize, maxSize));\n            }\n          }\n\n          const results = deterministicGroupingForModules({\n            maxSize: Math.max(minSize, maxSize),\n            minSize,\n            items: chunk.modulesIterable,\n\n            getKey(module) {\n              const ident = contextify(compilation.options.context, module.identifier());\n              const name = module.nameForCondition ? contextify(compilation.options.context, module.nameForCondition()) : ident.replace(/^.*!|\\?[^?!]*$/g, \"\");\n              const fullKey = name + automaticNameDelimiter + hashFilename(ident);\n              return fullKey.replace(/[\\\\/?]/g, \"_\");\n            },\n\n            getSize(module) {\n              return module.size();\n            }\n\n          });\n          results.sort((a, b) => {\n            if (a.key < b.key) return -1;\n            if (a.key > b.key) return 1;\n            return 0;\n          });\n\n          for (let i = 0; i < results.length; i++) {\n            const group = results[i];\n            const key = this.options.hidePathInfo ? hashFilename(group.key) : group.key;\n            let name = chunk.name ? chunk.name + automaticNameDelimiter + key : null;\n\n            if (name && name.length > 100) {\n              name = name.slice(0, 100) + automaticNameDelimiter + hashFilename(name);\n            }\n\n            let newPart;\n\n            if (i !== results.length - 1) {\n              newPart = compilation.addChunk(name);\n              chunk.split(newPart);\n              newPart.chunkReason = chunk.chunkReason; // Add all modules to the new chunk\n\n              for (const module of group.items) {\n                if (typeof module.chunkCondition === \"function\") {\n                  if (!module.chunkCondition(newPart)) continue;\n                } // Add module to new chunk\n\n\n                GraphHelpers.connectChunkAndModule(newPart, module); // Remove module from used chunks\n\n                chunk.removeModule(module);\n                module.rewriteChunkInReasons(chunk, [newPart]);\n              }\n            } else {\n              // change the chunk to be a part\n              newPart = chunk;\n              chunk.name = name;\n            }\n          }\n        }\n      });\n    });\n  }\n\n};","map":null,"metadata":{},"sourceType":"script"}